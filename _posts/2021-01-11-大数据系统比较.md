# 大数据系统比较

**整理者：**[孙挺](www.github.com/sunt-ing)

**原文：**[[大数据开源框架技术汇总](https://my.oschina.net/u/4417917/blog/4690895)](https://my.oschina.net/u/4417917/blog/4690895)

### 系统平台

| 名字   | 特点                                                         | 历史                                                         |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Hadoop | 将服务器与普通硬盘驱动器结合，并将它们转变为能够由 Java 应用程序兼容并行 IO 的分布式存储系统。主要包含分布式存储 HDFS、离线计算引擎 MapRduce、资源调度 Apache YARN 三部分。Hadoop2.0 引入了 Apache YARN 作为资源调度。Hadoop3.0 以后的版本对 MR 做了大量优化，增加了基于内存计算模型，提高了计算效率 | Hadoop 最早起源于 Nutch，Nutch 基于 2003 年、2004 年谷歌发表的两篇论文分布式文件系统 GFS 和分布式计算框架 MapReduce 的开源实现 HDFS 和 MapReduce。2005 年推出，2008 年 1 月成为 Apache 顶级项目。 |
| CDH    | 到目前为止，因为其易用、易于升级、安装组件和减少维护成本等特性，成为企业部署最广泛的大数据系统 | Cloudera 成立于 2008 年，在 2009 年发行了CDH                 |
| HDP    | Hortonworks 为入门提供了一个非常好的，易于使用的沙盒，使得 Hadoop 能够在包括 Windows Server 和 Windows Azure 在内的 Microsft Windows 平台上运行，而 CDH 只能运行在 Linux 系统中 | 2018 年 10 月 Cloudera 合并 Hortonworks，意味着 Hadoop 的标准将更加统一 |

### 集群管理与监控

| 名字            | 特点                                                         | 历史                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Clodera Manager | CM 是 Cloudera 开发的一个基于 Web 的用于部署和管理 CDH 集群的软件。它具有集群自动化安装、中心化管理、集群监控、报警等功能，大大节省集群部署时间，降低了运维成本，极大的提高集群管理的效率。 | 非开源                                                       |
| Hue             | 是一个可快速开发和调试 Hadoop 生态系统各种应用的一个基于浏览器的图形化用户接口。使用 Hue 可以在浏览器端的 Web 控制台上与 Hadoop 集群进行交互来分析处理数据，例如操作 HDFS 上的数据、运行 MapReduce Job、执行 Hive 的 SQL 语句、浏览 HBase 数据库、运行 Sqoop，编写 Oozie 工作流等等大量工作。Hue 是 Hadoop 平台大数据分析开发的可视化分析利器 | 是由 Cloudera 开源的 Hadoop UI 系统                          |
| Ambari          | 具备 Hadoop 组件的安装、管理、运维等基本功能，提供 Web UI 进行可视化的集群管理，简化了大数据平台的安装、使用难度 | 是 Hortonworks 贡献给 Apache 基金会的 Hadoop 平台管理软件，2013 年 11 月 20 日成为 Apache 顶级项目 |
| Dr.elephant     | Dr.elephant 是一款对 Hadoop 和 Spark 任务进行性能监控和调优的工具。它能自动采集作业的度量指标并分析，然后以简单明了的方式展现出来。Dr.elephant 的设计思想是通过作业分析结果来指导开发者进行作业调优，从而提升开发者效率和集群资源的利用率 | 它由 LinkedIn 的团队于 2016 年开源，开源之前已经在公司运行使用 2 年 |
| Ganglia         | 设计用于测量数以千计的节点。Ganglia 的核心包含 gmond、gmetad 以及一个 Web 前端。主要是用来监控系统性能，如：cpu 、mem、硬盘利用率， I/O 负载、网络流量情况等，通过曲线很容易见到每个节点的工作状态，对合理调整、分配系统资源，提高系统整体性能起到重要作用 | 是 UC Berkeley 发起的一个开源集群监视项目                    |
| Zabbix          | 通过 C/S 模式采集数据，通过 B/S 模式在 web 端展示和配置。它能够实时监控从成千上万台服务器、虚拟机和网络设备中收集到的数以百万计的指标。Zabbix 能监视各种网络参数，保证服务器系统的安全运营，并提供灵活的通知机制以让系统管理员快速定位 / 解决存在的各种问题。还能够利用存储数据提供杰出的报表及实时的图形化数据处理，实现对监控主机 7x24 小时集中监控 | 于 2004 年 zabbix 1.0 正式发布                               |
| Eagle           | 是一个开源监视和警报解决方案，用于智能实时地识别大数据平台上的安全和性能问题，例如 Apache Hadoop，Apache Spark 等。Eagle 主要包括：高可扩展、高可伸缩、低延时、动态协同等特点，支持数据行为实时监控，能立即监测出对敏感数据的访问或恶意的操作，并立即采取应对的措施。Eagle 提供一套高效分布式的流式策略引擎，具有高实时、可伸缩、易扩展、交互友好等特点，同时集成机器学习对用户行为建立 Profile 以实现实时智能实时地保护 Hadoop 生态系统中大数据的安全 | 于 2015 年 10 月提交给 Apache 孵化器，2016 年 12 月 21 日成为 Apache 顶级项目 |

### 文件系统

| 名字                                 | 特点                                                         | 历史                                                         |
| ------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| HDFS                                 | HDFS 放宽了一部分 POSIX 约束，来实现流式读取文件系统数据的目的。缺点：不适合低延迟数据访问、无法高效存储大量小文件、不支持多用户写入及任意修改文件 | 基于谷歌2004年提出的论文GFS                                  |
| GPFS（General Parallel File System） | IBM 认为 GPFS 不共享集群版本比 HDFS 快得多，因为它在内核级别中运行，而不是像 HDFS 在操作系统中运行。GPFS 是一个共享磁盘的文件系统，集群内的所有节点可以并行地访问所有共享磁盘，并通过分布式的 Token 管理机制和条带化技术来管理和优化节点的访问。GPFS 支持完整的 Posix 文件系统语义。GPFS 的应用范围非常广泛，从多节点文件共享服务、实时多媒体处理、到大型的高性能计算集群，我们都可以看到 GPFS 的优秀表现 | 是 IBM 推出的基于 Hadoop 的并行分布式集群文件系统            |
| Ceph                                 | Ceph 的主要目标是设计成基于 POSIX 的没有单点故障的分布式文件系统，使数据能容错和无缝的复制。2010 年 3 月，Linus Torvalds 将 Ceph client 合并到内核 2.6.34 中。它基于 CRUSH 算法，没有中心节点，可以无限扩展。Ceph 提供三种存储方式分别是对象存储，块存储和文件系统。在虚拟化领域里，比较常用到的是 Ceph 的块设备存储。Ceph 以其稳定、高可用、可扩展的特性，乘着开源云计算管理系统 OpenStack 的东风，迅速成为最热门的开源分布式存储系统。Ceph 是目前最火的分布式存储软件，Ceph 开源存储项目已经成为全球众多海量存储项目的主要选择。Ceph 现在是云计算、虚拟机部署的最火开源存储解决方案，是私有云事实上的标准 | Ceph 是加州大学 Santa Cruz 分校的 Sage Weil（DreamHost 的联合创始人）专为博士论文设计的新一代自由软件分布式文件系统。自 2007 年毕业之后，Sage 开始全职投入到 Ceph 开发之中，使其能适用于生产环境 |
| GlusterFS (GNU ClusterFile System)   | 是一种全对称的开源分布式文件系统，所谓全对称是指 GlusterFS 采用弹性哈希算法，没有中心节点，所有节点全部平等。GlusterFS 配置方便，稳定性好，可轻松达到 PB 级容量，数千个节点 | 2011 年被红帽收购                                            |
| Swift                                | Swift 构筑在比较便宜的标准硬件存储基础设施之上，无需采用 RAID（磁盘冗余阵列），通过在软件层面引入一致性散列技术和数据冗余性，牺牲一定程度的数据一致性来达到高可用性和可伸缩性，支持多租户模式、容器和对象读写操作，适合解决互联网的应用场景下非结构化数据存储问题 | 于 2010 年贡献给 OpenStack 开源社区作为其最初的核心子项目之一 |
| BeeGFS                               | 既是一个网络文件系统也是一个并行文件系统。是遵循 GPL 的 “免费开源” 产品，文件系统没有许可证费用 | 由 Fraunhofer Institute 为工业数学计算而设计开发，由于在欧洲和美国的中小型 HPC 系统性能表现良好，在 2014 年改名注册为 BeeGFS 并受到科研和商业的广泛应用 |
| Alluxio（原 Tachyon）                | 它统一了数据访问的方式，为上层计算框架和底层存储系统构建了桥梁， 应用只需要连接 Alluxio 即可访问存储在底层任意存储系统中的数据。此外，Alluxio 的以内存为中心的架构使得数据的访问速度能比现有方案快几个数量级。Alluxio 介于计算框架 (如 Apache Spark，Apache MapReduce，Apache HBase，Apache Hive，Apache Flink) 和现有的存储系统（如 Amazon S3，OpenStack Swift，GlusterFS，HDFS，MaprFS，Ceph，NFS，OSS）之间 | 诞生于 UC Berkeley 的 AMPLab                                 |

### 资源调度

| 名字                                    | 特点                                                         | 历史                                                         |
| --------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| YARN（Yet Another Resource Negotiator） | 它的出现其实是为了解决第一代 MapReduce 编程框架的不足，提高集群环境下的资源利用率，这些资源包括内存，磁盘，网络，IO 等。YARN 的基本思想是将资源管理和作业调度 / 监视的功能分解为单独的 daemon（守护进程），其拥有一个全局 ResourceManager、每个应用程序的 ApplicationMaster 及每台机器框架代理 NodeManager。ResourceManager 负责所有应用程序之间资源分配。NodeManager 负责 Containers，监视其资源使用情况（CPU，内存，磁盘，网络）并将其报告给 ResourceManager。ApplicationMaster 负责是协调来自 ResourceManager 的资源，并与 NodeManager 一起执行和监视任务 | YARN 是 Hadoop2.x 版本中的一个新特性                         |
| Mesos                                   | 它位于应用程序层和操作系统之间，可以更加轻松地在大规模集群环境中更有效地部署和管理应用程序。它可以在动态共享节点池上运行许多应用程序。对数据中心而言它就像一个单一的资源池，从物理或虚拟机器中抽离了 CPU、内存、存储以及其它计算资源，很容易建立和有效运行具备容错性和弹性的分布式系统 | 最初是由加州大学伯克利分校的 AMPLab 开发的，Mesos 项目发布于是 2009 年，2010 年 12 月进入 Apache 孵化器，2013 年 6 月 19 日成为 Apache 顶级项目。Twitter 公司则是 Mesos 项目的早期支持者和使用者之一。2019 年 5 月，Twitter 宣布放弃 Mesos，基础设施从 Mesos 全面转向 Kubernetes |

### 协调框架

| 名字      | 特点                                                         | 历史                                                         |
| --------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ZooKeeper | 是一个开源的分布式协调服务，是 Google 的 Chubby 一个开源的实现，是 Hadoop，HBase 和其他分布式框架使用的有组织服务的标准。ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布 / 订阅、负载均衡、命名服务、分布式协调 / 通知、集群管理、Master 选举、分布式锁和分布式队列等功能。ZooKeeper 是以 Fast Paxos 算法为基础的，Paxos 算法存在活锁的问题，即当有多个 proposer 交错提交时，有可能互相排斥导致没有一个 proposer 能提交成功，而 Fast Paxos 作了一些优化，通过选举产生一个 leader (领导者)，只有 leader 才能提交 proposer。ZooKeeper 使用 ZAB 协议作为其保证数据一致性的核心算法。ZAB（ZooKeeper Atomic Broadcast 原子广播）协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议 | 由雅虎开源并于 2010 年 11 月成为 Apache 顶级项目             |
| Etcd      | Etcd 是一种分布式 kv 存储设施，它类似的 Zookeeper，但没有 Zookeeper 那么重型，功能也没有覆盖那么多，通过 Raft 一致性算法处理日志复制以保证强一致性。Raft 是一个新的一致性算法，适用于分布式系统的日志复制，Raft 通过选举的方式来实现一致性。Google 的容器集群管理系统 Kubernetes、开源 PaaS 平台 Cloud Foundry 和 CoreOS 的 Fleet 都广泛使用了 Etcd。在分布式系统中，如何管理节点间的状态一直是一个难题，etcd 像是专门为集群环境的服务发现和注册而设计，它提供了数据 TTL 失效、数据改变监视、多值、目录监听、分布式锁原子操作等功能，可以方便的跟踪并管理集群节点的状态 | 由 CoreOS 于 2013 年 6 月发起的开源并维护的项目，它感来自于 ZooKeeper 和 Doozer，基于 Go 语言实现 |
| Consul    | 用于实现分布式系统的服务发现与配置共享。Consul 用 Go 语言实现，因此具有天然可移植性 (支持 Linux、windows 和 Mac OS X)。与其他分布式服务注册与发现的方案不同，Consul 的方案更 "一站式"，内置了服务注册与发现框架、分布一致性协议实现、健康检查、Key/Value 存储、多数据中心方案，不再需要依赖其他工具（比如 ZooKeeper 等）。采用 Raft 算法一致性协议，支持多数据中心分布式高可用，服务发现和配置共享，使用 gossip 协议管理成员和消息广播，支持 ACL 访问控制。最新的 Consul 提供了一个新特性 “Mesh 网关”，实现透明、跨网络的连接。这些特性可以跨平台工作，对 Kubernetes 提供一流的支持，并且在任何云或专用网络上都可以轻松地部署到更传统的环境中，实现了 Consul 多云服务网络的目标 | HashiCorp 公司推出的开源工具                                 |

### 数据存储

| 名字                     | 特点                                                         | 历史                                                         |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| HBase（Hadoop Database） | 是一个分布式的、面向列的 NoSQL 开源数据库。是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用 HBase 技术可在廉价 PC Server 上搭建起大规模结构化存储集群。初期的目标是弥补 MapReduce 在实时操作上的缺失，方便用户可随时操作大规模的数据集。HBase 原来是 Apache 的 Hadoop 项目的子项目，随着大数据与 NoSQL 的流行和迅速发展，2010 年 5 月 Apache HBase 脱离了 Hadoop 成为 Apache 基金的顶级项目。HBase 是 Google Bigtable 的开源实现，类似 Google Bigtable 利用 GFS 作为其文件存储系统，HBase 利用 Hadoop HDFS 作为其文件存储系统；Google 运行 MapReduce 来处理 Bigtable 中的海量数据，HBase 同样利用 Hadoop MapReduce 来处理 HBase 中的海量数据；Google Bigtable 利用 Chubby 作为协同服务，HBase 利用 Zookeeper 作为协调服务 |                                                              |
| Apache Cassandra         | 以 Amazon 专有的完全分布式 Dynamo 为基础，结合了 Google BigTable 基于列族的数据模型。P2P 去中心化的存储。很多方面都可以称之为 Dynamo 2.0。Cassandra 的主要特点就是它不是一个数据库，而是由一堆数据库节点共同构成的一个分布式网络服务，对 Cassandra 的一个写操作，会被复制到其它节点上去，对 Cassandra 的读操作，也会被路由到某个节点上面去读取。对于一个 Cassandra 群集来说，扩展性能是比较简单的事情，只管在群集里面添加节点就可以了。它提供了高可用性，没有单点故障。它是一个网络社交云计算方面理想的数据库 | 最初由 Facebook 开发，于 2008 年开源，2010 年 2 月 17 日成为 Apache 顶级项目 |
| ScyllaDB                 | 用 C++ 重写的 Cassandra，完全兼容 Apache Cassandra，拥有比 Cassandra 多 10x 倍的吞吐量，降低了延迟，在垃圾收集或者 Compaction 的时候不需要暂停 |                                                              |
| MongoDB                  | MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似 json 的 bjson 格式，因此可以存储比较复杂的数据类型。Mongo 最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。MongoDB 是专为可扩展性，高性能和高可用性而设计的数据库。它可以从单服务器部署扩展到大型、复杂的多数据中心架构。利用内存计算的优势，MongoDB 能够提供高性能的数据读写操作。MongoDB 的本地复制和自动故障转移功能使应用程序具有企业级的可靠性和操作灵活性 | 由 10gen 公司开发和维护。它使用 C++ 编写。2018 年 10 月 MongoDB 宣布将开源协议从 GNU AGPLv3 切换到 Server Side Public License (SSPL)，SSPL 明确要求托管 MongoDB 实例的云厂商要么获取商业许可证要么向社区开放其服务源码。随即，红帽宣布从 Red Hat Enterprise Linux（RHEL）8 中删除 MongoDB，Debian Linux 也已经从它的发行版中删除了 MongoDB |
| Apache Accumulo          | 是一个高性能可扩展的分布式 Key-Value 数据存储和检索系统。使用 Google BigTable 设计思路，基于 Apache Hadoop、Zookeeper 和 Thrift 构建。Accumulo 支持高效存储和检索的结构化数据，包括查询范围，并提供支持使用 Accumulo 表作为输入和输出的 MapReduce 作业。Accumulo 比简单的 key-values 数据库提供更丰富的数据模型，但不是完全的关系数据库 | 由美国国家安全局（NSA）于 2011 年捐赠给 Apache 基金会，2012 年 3 月 21 日成为 Apache 顶级项目 |
| Redis                    | 可以用作数据库、缓存和消息中间件                             | 是 Salvatore Sanfilippo 于 2009 年开发，2010 年 3 月 15 日起 Redis 的开发工作由 VMware 主持，2013 年 5 月开始由 Pivotal 赞助 |
| Apache Ignite            | 是一个以内存为中心的分布式数据库、缓存和处理平台，可以在 PB 级数据中，以内存级的速度进行事务性、分析性以及流式负载的处理。Ignite 提供了完整的 SQL、DDL 和 DML 的支持，可以使用纯 SQL 而不用写代码与 Ignite 进行交互，这意味着只使用 SQL 就可以创建表和索引，以及插入、更新和查询数据。有这个完整的 SQL 支持，Ignite 就可以作为一种分布式 SQL 数据库。Ignite 还提供了基于数据关联对数据进行分区的能力，并使用大规模并行处理来提高性能和可伸缩性。Ignite 还提供内置的流处理、分析和机器学习功能。它类似于一个关系型的内存数据库，可以像操作数据库一样操作内存缓存 | 2014 年 3 月 GridGain 公司将该软件 90% 以上的功能和代码开源，2014 年 10 月 GridGain 通过 Apache 2.0 许可进入 Apache 的孵化器进行孵化，2015 年 9 月 18 日成为 Apache 的顶级项目 |
| Apache Arrow             | 它设计的目的在于作为一个跨平台的数据层，来加快大数据分析项目的运行速度。它为平面和分层数据指定了独立于语言的标准化列式内存格式，可在现代硬件上进行高效的分析操作。它还提供了计算库和零拷贝流式消息传递和进程间通信。在分布式系统内部，每个系统都有自己的内存格式，大量的 CPU 资源被消耗在序列化和反序列化过程中，并且由于每个项目都有自己的实现，没有一个明确的标准，造成各个系统都在重复着复制、转换工作，这种问题在微服务系统架构出现之后更加明显，Arrow 的出现就是为了解决这一问题。它提供了一种跨平台应用的内存数据交换格式，是列式内存分析的事实标准 | 最初是基于 Apache Drill 项目的代码进行开发的，于 2016 年 2 月 17 日成为 Apache 顶级项目。它是列式内存分析的事实标准，由来自 Drill、Hadoop、HBase、Impala、Storm 等 13 个顶级开源项目的工程师们开发和完善 |
| Apache Geode             | Geode 是一个相当成熟、强健的的数据管理平台，提供实时的、一致的、贯穿整个云架构地访问数据关键型应用。Geode 跨多个进程汇集内存，CPU，网络资源和可选的本地磁盘，以管理应用程序对象和行为。Geode 自身功能比较多，首先它是一个基于 JVM 的 NoSQL 分布式数据处理平台，同时集中间件、缓存、消息队列、事件处理引擎、NoSQL 数据库于一身的分布式内存数据处理平台。可用来进行完成分布式缓存、数据持久化、分布式事物、动态扩展等功能。简单说，Geode 是 Redis 的增强版 | 2015 年 4 月 GemGire 把代码提交给 Apache 孵化，2016 年 11 月 16 日毕业成为 Apache 基金会的顶级项目 |
| Neo4j                    | 是一个开源的高性能 NOSQL 图形数据库，它将结构化数据存储在网络上而不是表中。它是由 Neo 技术使用 Java 语言完全开发的。图形数据库也就意味着它的数据并非保存在表或集合中，而是保存为节点以及节点之间的关系。Neo4j 除了顶点和边，还有一种重要的部分属性。无论是顶点还是边，都可以有任意多的属性。属性的存放类似于一个 HashMap，Key 为一个字符串，而 Value 必须是基本类型或者是基本类型数组。Neo4j 也可以被看作是一个高性能的图引擎，该引擎具有成熟数据库的所有特性。Neo4j 创建的图是用顶点和边构建一个有向图，其查询语言 cypher 已经成为事实上的标准 |                                                              |
| CouchDB                  | CouchDB 是一个完全包含 web 的数据库。使用 JSON 格式存储文档数据。使用 web 浏览器通过 HTTP 访问文档。使用 JavaScript 查询、组合和转换文档。CouchDB 可以很好地与现代 web 和移动应用程序配合使用。可以使用 CouchDB 增量复制高效地分发数据。CouchDB 支持带有自动冲突检测的主控设置。CouchDB 附带了一套特性，比如即时文档转换和实时更改通知，这使得 web 开发变得非常简单。它甚至提供了一个易于使用的 web 管理控制台 | 2008 年 11 月 19 日成为 Apache 顶级开源项目                  |
| Apache Kudu              | 是一个为了 Hadoop 系统环境而打造的列式存储系统，是一个为块数据的快速分析而生的存储架构，可以同时提供低延迟的随机读写和高效的数据分析能力。Kudu 专为了对快速变化的数据进行快速的分析，拥有 Hadoop 生态系统应用的常见技术特性，运行在一般的商用硬件上，支持水平扩展，高可用，使用 Raft 协议进行一致性保证。并且与 Cloudera Impala 和 Apache Spark 等当前流行的大数据查询和分析工具结合紧密。在 Kudu 出现之前，Hadoop 生态环境中的储存主要依赖 HDFS 和 HBase，追求高吞吐批处理的用例中使用 HDFS，追求低延时随机读取用例下用 HBase，而 Kudu 正好能兼顾这两者 | Kudu 是由 Cloudera 开源，2015 年 12 月 3 日进入 Apache 孵化器，2016 年 7 月 20 日成为 Apache 顶级项目 |
| Apache CarbonData        | CarbonData 是一种新的融合存储解决方案，利用先进的列式存储，索引，压缩和编码技术提高计算效率，从而加快查询速度，其查询速度比 PetaBytes 数据快一个数量级。CarbonData 提供了一种新的融合数据存储方案，以一份数据同时支持 “交互式分析、详单查询、任意维度组合的过滤查询等” 多种大数据应用场景，并通过丰富的索引技术、字典编码、列存等特性提升了 IO 扫描和计算性能，实现百亿数据级秒级响应，与大数据生态 Apache Hadoop、Apache Spark 等无缝集成 | 华为于 2016 年 6 月开源并贡献给 Apache，于 2017 年 4 月 19 日成为 Apache 顶级项目 |

### 数据处理

| 名字                    | 特点                                                         | 历史                                                         |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Hadoop MapReduce | MapReduce 框架使得编程人员在不会分布式并行编程的情况下，将编写的业务逻辑代码运行在分布式系统上，开发人员可以将绝大部分的工作集中于业务逻辑上的开发，具体的计算只需要交给框架就可以。MapReduce 的处理过程分为两个步骤：Map 和 Reduce。Map 阶段对输入的数据进行并行处理，处理结果传给 Reduce 完成最后的汇总。但由于 MR 对 HDFS 的频繁操作（包括计算结果持久化、数据备份、资源下载及 Shuffle 等）导致磁盘 I/O 成为系统性能的瓶颈，因此只适用于离线数据处理或批处理，而不能支持对迭代式、交互式、流式数据的处理，目前逐渐被 Spark、Flink 替代 |                                                              |
| Apache Spark            | Spark 是基于 MapReduce 算法实现的分布式计算，拥有 MapReduce 所具有的优点，但不同于 MR 的是，Job 中间输出和结果可以保存在内存中，从而不再需要读写 HDFS，因此 Spark 能更好地适用于数据挖掘与机器学习等需要迭代的算法中，高效地支持更多计算模式，包括交互式查询和流处理。Spark 是 MapReduce 的替代方案，是对 Hadoop 的补充，而且兼容 HDFS、Hive，可融入 Hadoop 的生态系统，以弥补 MapReduce 的不足。Spark 是在 Scala 语言中实现的，它将 Scala 用作其应用程序框架。与 Hadoop 不同，Spark 和 Scala 能够紧密集成，其中的 Scala 可以像操作本地集合对象一样轻松地操作分布式数据集。Spark 通过提供丰富的 Scala、Java、Python API、R 及交互式 Shell 来提高可用性。Spark 主要包含几个重要组件：SparkCore 批处理、SparkSQL 交互式处理、SparkStreaming 流处理、Spark Graphx 图计算、Spark MLlib 机器学习，Spark 旨在成为运行批处理、数据流处理、交互处理、图形处理和机器学习等应用的一站式平台。目前 Spark 已经成为大数据领域最热门的技术 | 2009 年诞生于 UC Berkeley 的 AMPLab，2010 年开源，2013 年 6 月成为 Apache 孵化项目，2014 年 2 月 19 日成为 Apache 顶级项目 |
| Apache Flink            | Flink 的概念和使用场合类似于 Spark，旨在成为运行批处理、数据流处理、交互处理、图形处理和机器学习等应用的一站式平台。Flink 不仅具有支持高吞吐、低延迟和 exactly-once 语义的实时计算能力，还有基于流式计算引擎处理批量数据的计算能力，真正意义实现了批流统一，同时 Flink 运行时本身也支持迭代算法的执行。Flink 流式计算模型实现了高吞吐，低延迟，高性能兼具实时流式计算框架，而且完全兼容 Hadoop。众多优秀的特性，使得 Flink 成为开源大数据数据处理框架中的一颗新星，在全球范围内，越来越多的公司开始使用 Flink，Flink 也渐渐成为企业内部主流的数据处理框架，逐渐成为下一代大数据数据处理框架标准的趋势 | Flink 起源于 Stratosphere 项目，2014 年 4 月 Stratosphere 代码被贡献给 Apache 软件基金会成为孵化器项目，2014 年 12 月 17 日成为 Apache 顶级项目，0.6 版本以后改名为 Flink，2015 年 09 月发布第一个稳定版本 0.9 |
| Apache Storm            | Storm 是用 Java 和 Clojure 编写，使用 Apache Thrift，能以任何语言编写拓扑 topology。Storm 提供了毫秒级别的实时数据处理能力。现在随着 Spark 和 Flink 的发展，Storm 市场占有逐渐在降低，但目前它仍然是实时分析的领导者 | Storm 最初由 Nathan Marz 创建，后来被 Twitter 收购并开源。2011 年 9 月 Storm 正式发布，2013 年 9 月进入 Apache 孵化并于 2014 年 9 月 17 日毕业成为 Apache 顶级项目，短时间内 Storm 成为了分布式实时处理系统的标准 |
| Apache Tez              | Apache Tez 是一个开源的支持 DAG 作业的计算引擎，它可以将多个有依赖的作业转换为一个作业从而大幅提升 DAG 作业的性能。Tez 是从 MapReduce 计算框架演化而来的通用 DAG 计算框架，可作为 MapReduce、Pig、Hive 等系统的底层数据处理引擎。简单来说，Tez 主要 Apache 和 HDP 平台替代 MR 和 Hive 底层执行引擎，提高计算效率 | Tez 是 Hortonworks 开发的 DAG 计算框架，是为了更高效地运行存在依赖关系的作业（比如 Pig 和 Hive 产生的 MapReduce 作业），减少磁盘和网络 IO。2014 年 7 月 16 日成为 Apache 顶级项目 |
| Apache Samza            | 是一种是分布式流处理框架，与 Apache Kafka 消息系统紧密绑定的流处理框架。它是一个分布式流处理框架，专用于实时数据的处理，非常像 Twitter 的流处理系统 Storm。不同的是 Samza 基于 Hadoop，而且使用了 LinkedIn 自家的 Kafka 分布式消息系统。Samza 的目标是将流作为接受到的消息处理，同时，Samza 的流初始元素并不是一个 tuple 或一个 DStream，而是一个消息，流被划分到分区，每个分区是一个只读消息的排序的序列，每个消息有一个唯一的 ID (offset)，系统也支持批处理，从同样的流分区以顺序消费几个消息，尽管 Samza 主要是依赖于 Hadoop 的 Yarn 和 Apache Kafka，但是它的 Execution & Streaming 模块是可插拔的 | 是 LinkedIn 于 2013 年 7 月开源并作为孵化项目贡献给 Apache，2015 年 1 月 21 日成为 Apache 顶级项目 |
| Apache Apex             | 作为新的开源数据流分析方案，Apex 脱胎于 DataTorrent 的 RTS 平台，能够带来出色的速度表现并简化编程要求。Apex 能够在 Hadoop 上实现数据流分析。其设计目标在于运行 Hadoop 生态系统，并利用 YARN 实现按需规模伸缩且通过 HDFS 实现容错能力 | 由 DataTorrent 在 2012 年创建，2015 年 8 月贡献给 Apache，2016 年 4 月 20 日成为 Apache 顶级项目 |
| Apache Beam             | Apache Beam 是一个开源的统一编程模型，用于定义和执行并行数据处理管道。Beam 主要是对数据处理的编程范式和接口进行了统一定义，这样基于 Beam 开发的数据处理程序可以执行在任意的分布式计算引擎上。誉为下一代的大数据处理统一标准。它的强大之处在于它能够同时运行批处理流和流式管道，并且由 Beam 支持的分布式处理后端之一执行：Apache Apex，Apache Flink，Apache Spark 和 Google Cloud Dataflow | Google 在 2016 年 2 月宣布将大数据流水线产品（Google DataFlow）贡献给 Apache 基金会孵化，2016 年 12 月 21 日成为 Apache 顶级项目，2017 年 5 月发布第一个稳定版本 2.0.0 |
| Apache Heron            | 是一个实时的、容错的、分布式的流数据处理系统。它继承了 Apache Storm 的实时性、容错、低延迟的特性。并且它保留了 Apache Storm 的 Topology API，使用者可以直接将 Apache Storm 上构建的 Topology 项目，直接转移到 Apache Storm 中运行而不需要做其他更改。它广泛应用于实时分析、连续计算、复杂事件处理和一些实时性要求的应用。相比于 Apache Storm，它提供了扩展性更好，调试能力更强，性能更好，管理更容易等特性。它能够每秒钟百万级别的吞吐量和毫秒级别的延迟 | Twitter 开发的第二代流处理系统，于 2016 年 5 月 25 日宣布开源。2017 年 6 月 23 日进入 Apache 孵化器。Twitter 宣称已经用 Heron 替换了 Storm。Heron 是 Apache Storm 的直接继承者 |

| 名字                             | 特点                                                         | 历史                                                         |
| -------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Hive                      | 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供类 SQL 语句的 Hive SQL（HQL）查询功能，将 SQL 语句转换为 MapReduce 任务进行运行。原理是用熟悉的 SQL 模型来操作 HDFS 上的数据 。优点是学习成本低，可以通过 HQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用。方便的使用 Hive 进行数据仓库的建模和建设，然后使用 SQL 模型针对数据仓库中的数据进行统计和分析。但由于 Hive 底层默认是转换为 MR 执行，而 MR 的 shuffle 是基于key的，所以只能处理离线分析，效率比较低。目前大部分企业使用 Hive 构建数仓 | Hive 是由 Facebook 在 2008 年将捐献给 Apache，2010 年 9 月毕业成为 Apache 顶级项目 |
| Apache SparkSQL                  | 它提供了一个叫做 DataFrames 的可编程抽象数据模型，并且可被视为一个分布式的 SQL 查询引擎。SparkSQL 替代的是 Hive 的查询引擎，且兼容 hive。跟基本的 Spark RDD 的 API 不同，Spark SQL 中提供的接口将会提供给 Spark 更多关于结构化数据和计算的信息。Spark SQL 底层是 Spark Core，这种意味着可以轻松地在不同的 SQL 和 API 之间进行切换 | Spark 团队在 2014 年发布了 Spark SQL，并吸收了一个的早期的 Hive-on-Spark 项目 Shark，迅速成为最广泛使用的 Spark 模块 |
| Presto                           | 是一个分布式的数据查询引擎。它本身并不存储数据，但是可以接入多种数据源，并且支持跨数据源的级联查询。Presto 是一个 OLAP 的工具，擅长对海量数据进行复杂的分析，但对于 OLTP 场景并不擅长，Presto 只有计算分析能力，所以不能把 Presto 当做数据库来使用。Presto 是一个低延迟高并发的内存计算引擎，相比 Hive，执行效率要高很多。是一种 MPP（Massively parallel processing 大规模并行处理）模型，能处理 PB 级数据。Presto 的原理是将数据的一些放在内存进行计算，完成后取出，再处理另一些数据，这样循环的类似流水线的处理模式 | 是 Facebook 于 2012 年开发，2013 年开源的分布式 SQL 交互式查询引擎。 |
| Apache Kylin                     | Apache Kylin 是 Hadoop 大数据平台上一个开源的分布式分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及 OLAP 能力以支持超大规模数据。它采用 Cube 预计算技术，可以将某些场景下的大数据 SQL 查询速度提升到亚秒级别。Kylin 它的出现就是为了解决大数据系统中 TB 级别的数据分析需求，主要是对 hive 中的数据进行预计算，利用 hadoop 的 MapReduce 框架实现，它能在亚秒内查询巨大的 Hive 表。在 Kylin 中最关键的两个流程是 Cube 的预计算过程和 SQL 查询转换成 Cube 的过程，尽量多地预先计算聚合结果，在查询时尽量利用预计算的结果得出查询结果，从而避免直接扫描可能无限增大的原始记录 | Kylin 始创于 eBay，并在 2014 年 11 月加入 Apache 孵化器，2015 年 12 月 8 日成为 Apache 顶级项目，是第一个中国团队主导贡献的顶级项目 |
| Apache Impala                    | 是一个实时交互 SQL 大数据查询引擎。Impala 使用完全开放的形式融入 Hadoop 生态，允许用户使用 SQL 操作 Hadoop 中的海量数据，目前已经支持更多存储选择，比如：Apache Kudu、Amazon S3、Microsoft ADLS、本地存储等。最初 Impala 仅支持 HDFS 海量数据的交互式分析，其灵活性和领先的分析型数据库性能推动了 Impala 在全球企业中的大量部署。为企业业务提供 BI 和交互式 SQL 高效率分析支持，让支持 Impala 的第三方生态系统快速增长。与 Apache Kudu 项目，进一步巩固了 Cloudera 在开源 SQL 领域的地位 | 是 Cloudera 在受到 Google 的 Dremel 启发下开发的 SQL On Hadoop 开源 MPP 查询工具，2012 年 10 月开源，于 2017 年 11 月 28 日晋升为 apache 顶级项目 |
| Apache Druid                     | Apache Druid 是一个开源的实时大数据分析引擎，旨在快速处理大规模的数据，并能够实现快速查询和分析。用于解决如何在大规模数据集下进行快速的、交互式的查询和分析。Druid 就是为了解决海量数据上的实时分析，它提供了以交互方式访问数据的能力，数据可以实时摄入，进入到 Druid 后立即可查，同时数据是几乎是不可变。通常是基于时序的事实事件，事实发生后进入 Druid，外部系统就可以对该事实进行查询 | 是 Metamarkets 推出的一个分布式内存实时分析系统，2018 年 2 月 28 日进入 Apache 孵化器 |
| Elastic Search                   | 是一个分布式可扩展的实时搜索和分析引擎，是一个建立在 Apache Lucene 基础上的搜索引擎。。它提供了一个分布式多用户能力的全文搜索引擎，基于 RESTful web 接口。ES 的实现原理主要分为以下几个步骤，首先用户将数据提交到 ES 数据库中，再通过分词控制器去将对应的语句分词，将其权重和分词结果一并存入数据，当用户搜索数据时候，再根据权重将结果排名，打分，再将返回结果呈现给用户。ES 是用 Java 开发的，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便 | 由 Shay Banon 在 2010 年创建并开源，后来 Shay 和合伙人成立了公司专注打造 ES，他们对 ES 进行了一些商业化的包装和支持 |
| Apache HAWQ（Hadoop With Query） | 是一个 Hadoop 原生大规模并行 SQL 分析引擎，针对的是分析性应用。HAWQ 是 Hadoop 原生 SQL 查询引擎，结合了 MPP 数据库的关键技术优势和 Hadoop 的可扩展性和便捷性。官方宣称 HAWQ 做 OLAP 高于 Hive 和 Impala 性能 4 倍以上。它非常适合用于 Hadoop 平台上快速构建数据仓库系统。HAWQ 具有大规模并行处理、完善的 SQL 兼容性、支持存储过程和事务、出色的性能表现等特性，还可与开源数据挖掘库 MADLib 机器学习库轻松整合，从而使用 SQL 就能进行数据挖掘与机器学习 | HAWQ 是 Pivotal 在 2012 年推出了一款商业许可的高性能 SQL 引擎，于 2015 年 6 月将项目捐献给了 Apache，并于 2015 年 9 月进入了 Apache 孵化器，2018 年 8 月 15 日成为 Apache 顶级项目 |
| Apache Lucene                    | 是一套开源的基于 Java 的用于全文检索和搜寻的引擎工具包，是一种功能强大且被广泛使用的搜索引擎。Lucene 并不是一个完整的搜索引擎产品，而是一个全文检索引擎的架构，可以用来制作搜索引擎产品。它是一个全文检索引擎的架构，提供了完整的创建索引和查询索引，以及部分文本分析的引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene 提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在 Java 开发环境里 Lucene 是一个成熟的免费开放源代码工具 | 由资深全文检索专家 Doug Cutting 在 2000 年 3 月创建开源，在 2001 年 9 月加入 Apache 的 Jakarta 家族中 |
| Apache Solr                      | Solr 具有高可靠性，可扩展性和容错性，可提供分布式索引，复制和负载均衡查询，自动故障转移和恢复以及集中配置等特性。Solr 是用 Java 编写、运行在 Servlet 容器（如 Apache Tomcat 或 Jetty）的一个独立的全文搜索服务器。Solr 采用了 Lucene Java 搜索库为核心的全文索引和搜索，并具有类似 REST 的 HTTP/XML 和 JSON 的 API。Solr 强大的外部配置功能使得无需进行 Java 编码，便可对其进行调整以适应多种类型的应用程序。Solr 为世界上许多大型互联网站点提供搜索和导航功能 | 2004 年发布，2007 年 1 月 17 日成为 Apache 顶级项目          |
| Apache Phoenix                   | 是构建在 HBase 之上的 SQL 框架，可以使用标准的 JDBC 的 API 去代替常规的 HBase 客户端的 API 去创建表，插入数据和查询 HBase 数据。它一个 Java 中间层，可以让开发者通过 Phoenix 可以像使用 MySQL 等关系型数据库一样使用 HBase 中的数据表。Phoenix 会将用户编写的 SQL 查询编译为一系列的 Scan 操作，最终产生通用的 JDBC 结果集返回给客户端。它充分利用了 HBase 协处理器和过滤器等底层，小范围的查询在毫秒级响应，千万数据的话响应速度为秒级 | 由 Saleforce 在 2013 年捐献给 Apache，2014 年 5 月项目毕业成为顶级项目 |

### 数据收集

| 名字          | 特点                                                         | 历史                                                         |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Flume  | 是一个分布式海量日志采集、聚合和传输系统。Flume 支持在日志系统中定制各类数据发送方，用于收集数据，同时，Flume 提供对数据进行简单处理，并写到各种数据接受方（可定制）的能力。Flume 的数据流由事件（Event）贯穿始终。事件是 Flume 的基本数据单位，它携带日志数据（字节数组形式）并且携带有头信息，这些 Event 由 Agent 外部的 Source 生成，当 Source 捕获事件后会进行特定的格式化，然后 Source 会把事件推入（单个或多个）Channel 中。可以把 Channel 看作是一个缓冲区，它将保存事件直到 Sink 处理完该事件。Sink 负责持久化日志或者把事件推向另一个 Source | Flume 最初由 Cloudera 由开发，于 2011 年 6 月贡献给 Apache，2012 年成为 Apache 顶级项目 |
| Filebeat      | Filebeat 是一个轻量级日志传输工具，它监视日志目录或特定日志文件（Tail File），并将它们转发给 Logstash、Elasticsearch、Kafka、Redis 等中。其作用是收集业务服务器的日志，输出到一个日志系统便于集中管理。Filebeat 是 Elastic Stack 的一部分，因此能够与 Logstash、Elasticsearch 和 Kibana 无缝协作。无论您要使用 Logstash 转换或充实日志和文件，还是在 Elasticsearch 中随意处理一些数据分析，亦或在 Kibana 中构建和分享仪表板，Filebeat 都能轻松地将您的数据发送至最关键的地方。Filebeat 占用资源少，而且安装配置也比较简单，支持目前各类主流 OS 及 Docker 平台 |                                                              |
| Logstash      | 是一个具有实时管道功能的开源数据收集引擎。它可以动态地将来自不同数据源的数据统一起来，并将数据规范化到选择的目的地。可以用它来统一对应用程序日志进行收集管理，提供 Web 接口用于查询和统计。Logstash 作为一个数据管道中间件，支持对各种类型数据的采集与转换，并将数据发送到各种类型的存储库 |                                                              |
| Apache Chukwa | 它是构建在 hadoop 的 hdfs 和 MapReduce 框架之上的，继承了 Hadoop 的可伸缩性和健壮性。Chukwa 还包含了一个强大和灵活的工具集，可用于展示、监控和分析已收集的数据。Chukwa 用于管理大型分布式系统的数据收集系统 (2000 + 以上的节点， 系统每天产生的监控数据量在 T 级别) | 2010 年 7 月 14 日进入 Apache 孵化器，2013 年 9 月 27 日成为 Apache 顶级项目 |

### 数据交换

| 名字         | 特点                                                         | 历史                                                         |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Sqoop | 是一款数据迁移工具，用来在不同数据存储软件之间进行数据传输的开源软件，它支持多种类型的数据储存软件。用来在关系型数据库和 Hadoop/Hive 间进行数据迁移，方便大量数据的导入导出工作。Sqoop 底层是通过 MapReduce 去实现的，但只有 Map 没有 Reduce | Sqoop 项目开始于 2009 年，最早是作为 Hadoop 的一个第三方模块存在，后来独立成为一个 Apache 项目，于 2012 年 3 月成为 Apache 顶级项目 |
| Kettle       | 是一款国外开源的 ETL 工具，纯 java 编写，可以在 Window、Linux、Unix 上运行，数据抽取高效稳定。可以将各种类型数据作为数据流，经过处理后再生成各种类型的数据 |                                                              |
| DataX        | 离线数据同步工具 / 平台，致力于实现包括关系型数据库 (MySQL、Oracle 等)、HDFS、Hive、ODPS、HBase、FTP 等各种异构数据源之间稳定高效的数据同步功能 | 阿里巴巴开源                                                 |
| Apache NiFi  | 是一个易于使用、功能强大而且可靠的数据拉取、数据处理和分发系统。基于 Web 图形界面，通过拖拽、连接、配置完成基于流程的编程，实现数据采集等功能。是为数据流设计。它支持高度可配置的指示图的数据路由、转换和系统中介逻辑，支持从多种数据源动态拉取数据。NiFi 是基于 Java 的，使用 Maven 支持包的构建管理。NiFi 基于 Web 方式工作，后台在服务器上进行调度。用户可以为数据处理定义为一个流程，然后进行处理，后台具有数据处理引擎、任务调度等组件 | NiFi 是美国国家安全局 NAS 开发并使用了 8 年的可视化数据集成产品，2014 年贡献给了 Apache 社区，2015 年成为 Apache 顶级项目 |

### 消息系统

| 名字            | 特点                                                         | 历史                                                         |
| --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Pulsar   | Pulsar 在消息、计算和存储三个方面进行的协调、抽象和统一。Pulsar 对 pub-sub 和 queue 两种模式提供统一的支持，同时保证了一致性，高性能和易扩展性。Pulsar 同时支持处理实时流和消息队列，内部的 Pulsar-Functions 提供了 Stream-native 的轻量级计算框架，保证了数据的即时流式处理。Pulsar 借助 Apache BookKeeper 提供了以 segment 为中心的存储架构，保证了存储的性能，持久性和弹性。Pulsar 是无状态的，在 Pulsar 架构中，数据的分发和保存是相互独立的。broker 从生产者接收数据，然后将数据发送给消费者，但数据是保存在 BookKeeper 中的。Pulsar 支持跨域复制。Pulsar 是下一代分布式消息队列，有替代 Kafka 的趋势 | 2015 年由 Yahoo 开源，2017 年 6 月提交给 Apache 孵化器，2018 年 9 月成为 Apache 的顶级项目 |
| Apache Kafka    | Apache Kafka 是一个发布 / 订阅的消息系统，由 Scala 写成。该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。Kafka 是一个分布式的、分区的、多复本的日志提交服务。是目前使用最广泛的消息系统。 | Kafka 最初是由 LinkedIn 开发，并于 2011 年初开源，2012 年 10 月从 Apache 毕业成为顶级项目 |
| Apache RocketMQ | 是一款分布式、队列模型的消息中间件。它借鉴参考了 JMS 规范的 MQ 实现，更参考了优秀的开源消息中间件 Kafka，并且结合阿里实际业务需求在天猫双十一的场景，实现业务削峰，分布式事务的优秀框架。它提供了丰富的消息拉取模式，高效的订阅者水平扩展能力，实时的消息订阅机制，亿级消息堆积能力，且具备了连接其它顶级开源生态（如 Spark、Ignite 和 Storm 等）能力 | 是阿里巴巴在 2012 年开源，于 2016 年 11 月成为 Apache 孵化项目， 2017 年 9 月 25 日成为 Apache 顶级项目 |
| Apache ActiveMQ | 不够轻巧，支持持久化到数据库，对队列数较多的情况支持不好     | 2007 年成为 Apache 顶级项目                                  |
| RabbitMQ        | 是基于 AMQP 实现的一个开源消息组件，主要用于在分布式系统中存储转发消息。是一个消息代理和队列服务器，可以在完全不同的应用之间共享数据。使用 Erlang 语言开发，具有很好的并发优势，性能较好。支持消息持久化 |                                                              |

### 任务调度

| 名字           | 特点                                                         | 历史                                                         |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Azkaban        | 一个批量工作流任务调度器。使用 Java 开发。用于在一个工作流内以一个特定的顺序运行一组工作和流程。Azkaban 定义了一种 KV 文件格式来建立任务之间的依赖关系，并提供一个易于使用的 web 用户界面维护和跟踪工作流。Azkaban 通过 Web 浏览器在 GUI 中进行基于时间的调度，将所有正在运行的工作流的状态保存在其内存中 | 由 Linkedin 开源                                             |
| Apache Oozie   | 是一个基于 Hadoop 的企业级工作流调度框架。Oozie 是 Cloudeara 贡献给 Apache 的顶级项目。它关注灵活性和创建复杂的工作流程，允许由时间，事件或数据可用性触发作业，可以通过命令行、Java API、Web 浏览器，以及 GUI 操作。它以 XML 的形式写调度流程，可以调度 MR、Hive、Spark、Pig、Shell、Jar 等等。Oozie 将所有正在运行的工作流的状态保存 SQL 数据库，仅将其内存用于状态事务。相比于 Azkaban，Oozie 属于重量级的任务调度工具 |                                                              |
| Apache Airflow | 是一个灵活，可扩展的工作流自动化和调度系统，是基于 DAG 的一种调度器，可编译和管理数百 PB 的数据。Airflow 可以轻松地协调复杂的计算工作流程，通过智能调度，数据库和依赖关系管理，错误处理和日志记录，可以自动化从单个服务器到大型群集的资源管理。该项目是用 Python 编写的，具有高度可扩展性，能够运行用其他语言编写的任务，并允许与常见的体系结构和项目集成，如 AWS S3，Docker，Kubernetes，MySQL，Postgres 等 | Airflow 最初由 Airbnb 于 2014 年创建，2016 年 3 月提交给 Apache 孵化器，2019 年 1 月成为 Apache 顶级项目 |

### 数据治理

| 名字          | 特点                                                         | 历史                                                         |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Ranger | 用在 Hadoop 平台上并提供操作、监控、管理综合数据安全的框架，它提供一个集中的管理机制，管理基于 Apache Hadoop 生态圈的所有数据权限。随着 Apache YARN 的出现，Hadoop 平台现在可以支持一个真正的数据湖体系结构。企业可以在多租户环境中运行多个工作负载，因此， Hadoop 中的数据安全性需要发展。Apache Ranger 提供最全面的安全覆盖，本地支持众多 Apache 项目，包括 Atlas、HDFS、HBase、Hive、Kafka、Knox、NiFi、Solr、Storm 和 YARN。Ranger 通过访问控制策略提供了一种标准的授权方法。作为标准，Ranger 提供了一种集中式的组件，用于审计用户的访问行为和管理组件间的安全交互行为。Ranger 使用了一种基于属性的方法定义和强制实施安全策略。当与 Apache Hadoop 的数据治理解决方案和元数据仓储组件 Apache Atlas 一起使用时，它可以定义一种基于标签的安全服务，通过使用标签对文件和数据资产进行分类，并控制用户和用户组对一系列标签的访问 | Ranger 是由 Hortonworks 所主导，2014 年 7 月 24 日进入 Apache 孵化，2017 年 1 月 18 日成为 Apache 的顶级项目 |
| Apache Sentry | 是一个为 Hadoop 集群元数据和数据存储提供集中、细粒度的访问控制项目。初衷是为了让用户能够细粒度的控制 Hadoop 系统中的数据，所以 Sentry 对 HDFS，Hive 以及同样由 Cloudera 开发的 Impala 有着很好的支持性。Sentry 旨在成为 Hadoop 各组件的可插拔授权引擎。它允许您定义授权规则以验证用户或应用程序对 Hadoop 资源的访问请求。Sentry 是高度模块化的，可以支持 Hadoop 中各种数据模型的授权。Sentry 是一个 RPC 服务，将认证元数据信息存储在关系型数据库，并提供 RPC 接口检索和操作权限 | 由 Cloudera 开发，2013 年 8 月成为 Apache 的孵化项目，2016 年 3 月 16 日成为 Apache 顶级项目 |
| Apache Atlas  | 是 Apache Hadoop 的数据和元数据治理的框架，是为解决 Hadoop 生态系统的元数据治理问题而产生的开源项目。它为 Hadoop 集群提供了包括数据分类、集中策略引擎、数据血缘、安全和生命周期管理在内的元数据治理核心登能力。Atlas 是一组可伸缩和可扩展的核心基础治理服务，使企业能够有效和高效地满足 Hadoop 中的遵从性需求，并允许与整个企业数据生态系统进行集成。Atlas 用于管理共享元数据、数据分级、审计、安全性以及数据保护等方面，与 Apache Ranger 整合，用于数据权限控制策略 | 是 Hortonworks 公司联合其他厂商与用户于 2015 年发起数据治理倡议，2015 年 5 月 5 日进入 Apache 孵化，2017 年 6 月 21 日成为 Apache 顶级项目 |

### 数据可视化

| 名字                                        | 特点                                                         | 历史                                          |
| ------------------------------------------- | ------------------------------------------------------------ | --------------------------------------------- |
| Kibana                                      | 是一个设计出来用于和 Elasticsearch 一起使用的开源的分析与可视化平台，可以用 Kibana 搜索、查看、交互存放在 Elasticsearch 索引里的数据，使用各种不同的图表、表格、地图等展示高级数据分析与可视化，基于浏览器的接口使你能快速创建和分享实时展现 Elasticsearch 查询变化的动态仪表盘，让大量数据变得简单，容易理解。Kibana 现在是 Elastic 的 ELK 家族成员之一 |                                               |
| D3.js                                       | D3（Data-Driven Documents 数据驱动文档）是一个开源数据可视化项目，D3 其实就是一个 JavaScript 的函数库，被称为一个互动和动态的数据可视化库网络。D3 项目的代码托管于 GitHubJavaScript 文件的后缀名通常为 .js，故 D3 也常使用 D3.js 称呼。D3 提供了各种简单易用的函数，大大简化了 JavaScript 操作数据的难度。由于它本质上是 JavaScript ，所以用 JavaScript 也可以实现所有功能的，但它能大大减小了工作量，尤其是在数据可视化方面，D3 已经将生成可视化的复杂步骤精简到了几个简单的函数，只需要输入几个简单的数据，就能够转换为各种绚丽的图形。D3 利用可缩放矢量图形或 SVG 格式，允许您渲染可放大或缩小的形状，线条和填充，而不会降低质量 | 由纽约时报的工程师在 2011 年 2 月首次发布     |
| ECharts（Enterprise Charts 商业产品图表库） | 是一个提供商业产品常用图表的纯 Javascript 的图表库。它可以流畅的运行在 PC 和移动设备上，兼容当前绝大部分浏览器，底层依赖轻量级的矢量图形库 ZRender，提供直观，交互丰富，可高度个性化定制的数据可视化图表 | 由百度开源，于 2018 年 1 月进入 Apache 孵化器 |

### 数据挖掘

| 名字               | 特点                                                         | 历史                                                         |
| ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Apache Mahout      | 是机器学习和数据挖掘的一个分布式框架，它是基于 hadoop 之上的。它提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout 包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘，主要核心的三大算法为推荐，聚类及分类算法。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中 |                                                              |
| Apache MADlib      | 是一个基于 SQL 的数据库内置的可扩展的机器学习库。MADlib 提供了精确的数据并行实现、统计和机器学习方法对结构化和非结构化数据进行分析。提供了丰富的分析模型，包括回归分析，决策树，随机森林，贝叶斯分类，向量机，风险模型，KMEAN 聚集，文本挖掘，数据校验等。In-Database Analytics 的特性使其大大扩展了数据库的分析功能，充分利用 MPP 架构使其能够快速处理海量数据集。MADlib 可以与 Apache HAWQ、PostgreSQL 和 Greenplum 等数据库系统无缝集成。DBAer 不用现学 Python、R 或 MATLAB，只要使用 MADlib，用 SQL 就能实现简单的数据挖掘 | 是 Pivotal 公司与 UCBerkeley 合作开发，2015 年 9 月进入 Apache 孵化器，于 2017 年 7 月 19 日毕业成为 Apache 顶级项目 |
| Apache Spark MLlib | 是 Spark 的机器学习库，是 Apache Spark 的一个组成模块。MLlib 由一些通用的学习算法和工具组成，包括分类、回归、聚类、协同过滤、降维等，同时还包括底层的优化原语和高层的管道 API。Spark 设计的初衷就是用来进行迭代计算。它基于内存的计算模型天生就擅长迭代计算，多个步骤计算直接在内存中完成，只有在必要时才会操作磁盘和网络，所以说 Spark 正是机器学习的理想的平台。利用 Spark 基于内存迭代计算、机器学习的优势，使用 Spark 处理数据挖掘将会更显得有价值。MLllib 目前分为两个代码包：spark.mllib 库基于 RDD 的原始算法 API；spark.ml 库基于 DataaFrame 的高层次的 API。Spark2.0 以后，Spark MLlib 进入维护不再更新，预计 Spark3.0 以后被废除，完全转向 Spark ML |                                                              |
| TensorFlow         | 是一个开源的基于数据流图的机器学习框架，它是 Google Brain 的第二代机器学习系统，常被应用于各种感知、语言理解、语音识别、图像识别等多项机器深度学习领域。TensorFlow 是一个采用数据流图（Data Flow Graphs），用于数值计算的开源软件库。节点（Nodes）在图中表示数学操作，张量（Tensor）代表了多维数组，图中的线（Edges）则表示在节点间相互联系的多维数据数组，即张量，流（Flow）代表了基于数据流图的计算。它灵活的架构让你可以在多种平台上展开计算，例如台式计算机中的一个或多个 CPU（或 GPU），服务器，移动设备等等。TensorFlow 最初由 Google 大脑小组（隶属于 Google 机器智能研究机构）的研究员和工程师们开发出来，用于机器学习和深度神经网络方面的研究，但这个系统的通用性使其也可广泛用于其他计算领域 |                                                              |
| Keras              | 是一个基于 TensorFlow 的深度学习库，其特点是对用户友好的，并且能够提供简易和快速的原型设计。Keras 是一个由 Python 编写的开源人工神经网络库，可以作为 Tensorflow、Microsoft-CNTK 和 Theano 的高阶应用程序接口，进行深度学习模型的设计、调试、评估、应用和可视化。Keras 为支持快速实验而生，能够把你的 idea 迅速转换为结果 |                                                              |

### 云平台

| 名字                                        | 特点                                                         | 历史 |
| ------------------------------------------- | ------------------------------------------------------------ | ---- |
| Amazon S3（Amazon Simple Storage Service ） | 是一种对象存储服务，提供行业领先的可扩展性、数据可用性、安全性和性能。这意味着各种规模和行业的客户都可以使用它来存储和保护各种用例（如网站、移动应用程序、备份和还原、存档、企业应用程序、IoT 设备和大数据分析）的任意数量的数据。Amazon S3 提供了易于使用的管理功能，因此您可以组织数据并配置精细调整过的访问控制以满足特定的业务、组织和合规性要求。 |      |
| GCP（Google Cloud Platform）                | 是 Google 提供的一套云计算服务。它提供一系列模块化云服务，包括计算、数据存储、数据分析和机器学习。Google 把运行各种网络应用所需要的一切基础架构，包括服务器、操作系统、应用软件、网站架构、API 接口、数据库、CDN、VPN、物联网、大数据等等全部预先准备好。你只需要在 google 云平台上注册一个帐号，即可在分布在全球各地数十个 google 机房使用所有的基础架构服务 |      |
| Microsoft Azure                             | Azure 是 Microsoft 提供的企业级云计算平台。Azure 的主要目标是为开发者提供一个平台，帮助开发可运行在云服务器、数据中心、Web 和 PC 上的应用程序。云计算的开发者能使用微软全球数据中心的储存、计算能力和网络基础服务 |      |







